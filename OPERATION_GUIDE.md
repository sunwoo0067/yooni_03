# ë“œëì‰¬í•‘ ìë™í™” ì‹œìŠ¤í…œ ìš´ì˜ ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ì¼ì¼ ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸](#ì¼ì¼-ìš´ì˜-ì²´í¬ë¦¬ìŠ¤íŠ¸)
2. [ì„±ê³¼ ëª¨ë‹ˆí„°ë§](#ì„±ê³¼-ëª¨ë‹ˆí„°ë§)
3. [ë¹„ìš© ìµœì í™”](#ë¹„ìš©-ìµœì í™”)
4. [ë³´ì•ˆ ê´€ë¦¬](#ë³´ì•ˆ-ê´€ë¦¬)
5. [ë°±ì—… ë° ë³µêµ¬](#ë°±ì—…-ë°-ë³µêµ¬)
6. [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)
7. [ìŠ¤ì¼€ì¼ë§ ì „ëµ](#ìŠ¤ì¼€ì¼ë§-ì „ëµ)
8. [ë²•ì  ì¤€ìˆ˜ì‚¬í•­](#ë²•ì -ì¤€ìˆ˜ì‚¬í•­)

## âœ… ì¼ì¼ ìš´ì˜ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ğŸŒ… ì˜¤ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸ (9:00-10:00)

#### 1. ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
```bash
# ì‹œìŠ¤í…œ í—¬ìŠ¤ ì²´í¬
python scripts/health_check.py

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
systemctl status dropshipping-*
docker ps --filter "name=dropshipping"

# ë¡œê·¸ í™•ì¸
tail -n 100 logs/system.log | grep ERROR
```

#### 2. ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì ê²€
```sql
-- ì—°ê²° ìˆ˜ í™•ì¸
SELECT count(*) FROM pg_stat_activity;

-- í…Œì´ë¸” í¬ê¸° í™•ì¸
SELECT 
    schemaname,
    tablename,
    pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as size
FROM pg_tables 
WHERE schemaname = 'public'
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- ëŠë¦° ì¿¼ë¦¬ í™•ì¸
SELECT query, mean_time, calls 
FROM pg_stat_statements 
ORDER BY mean_time DESC 
LIMIT 10;
```

#### 3. ì•¼ê°„ ì‘ì—… ê²°ê³¼ í™•ì¸
```python
# scripts/daily_morning_check.py
import asyncio
from src.monitoring.daily_report import DailyReportGenerator

async def morning_check():
    report_gen = DailyReportGenerator()
    
    # ì•¼ê°„ ìƒí’ˆ ìˆ˜ì§‘ ê²°ê³¼
    collection_report = await report_gen.get_collection_summary()
    print(f"ìˆ˜ì§‘ëœ ìƒí’ˆ: {collection_report['total_products']}ê°œ")
    print(f"ì„±ê³µë¥ : {collection_report['success_rate']}%")
    
    # ë“±ë¡ í˜„í™©
    registration_report = await report_gen.get_registration_summary()
    print(f"ë“±ë¡ëœ ìƒí’ˆ: {registration_report['total_registered']}ê°œ")
    
    # ì£¼ë¬¸ í˜„í™©
    order_report = await report_gen.get_order_summary()
    print(f"ì‹ ê·œ ì£¼ë¬¸: {order_report['new_orders']}ê±´")
    print(f"ì²˜ë¦¬ ëŒ€ê¸°: {order_report['pending_orders']}ê±´")
    
    return {
        'collection': collection_report,
        'registration': registration_report,
        'orders': order_report
    }

if __name__ == "__main__":
    report = asyncio.run(morning_check())
    
    # ì´ìƒ ìƒí™© ì•Œë¦¼
    if report['collection']['success_rate'] < 90:
        send_alert("ìƒí’ˆ ìˆ˜ì§‘ ì„±ê³µë¥  ì €í•˜", report['collection'])
    
    if report['orders']['pending_orders'] > 50:
        send_alert("ì²˜ë¦¬ ëŒ€ê¸° ì£¼ë¬¸ ì¦ê°€", report['orders'])
```

#### 4. ê³„ì • ìƒíƒœ í™•ì¸
```python
# scripts/account_status_check.py
from src.security.account_manager import AccountManager

async def check_account_status():
    account_manager = AccountManager()
    
    # ê° í”Œë«í¼ë³„ ê³„ì • ìƒíƒœ
    platforms = ['coupang', 'naver', '11st']
    
    for platform in platforms:
        accounts = await account_manager.get_platform_accounts(platform)
        
        for account in accounts:
            status = await account_manager.check_account_health(account['id'])
            
            print(f"{platform} - {account['name']}:")
            print(f"  ìƒíƒœ: {status['status']}")
            print(f"  ì¼ì¼ ì‚¬ìš©ëŸ‰: {status['daily_usage']}/{status['daily_limit']}")
            print(f"  API ì‘ë‹µì‹œê°„: {status['avg_response_time']}ms")
            
            if status['status'] != 'active':
                send_alert(f"{platform} ê³„ì • ë¬¸ì œ", status)
```

### ğŸ• ì£¼ê°„ ì²´í¬ë¦¬ìŠ¤íŠ¸ (ì›”ìš”ì¼ ì˜¤ì „)

#### 1. ì„±ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸
```python
# scripts/weekly_performance_analysis.py
from src.performance_analysis.sales_analyzer import SalesAnalyzer
from datetime import datetime, timedelta

async def weekly_analysis():
    analyzer = SalesAnalyzer()
    
    # ì§€ë‚œ ì£¼ ì„±ê³¼
    end_date = datetime.now()
    start_date = end_date - timedelta(days=7)
    
    weekly_report = await analyzer.generate_weekly_report(start_date, end_date)
    
    print("=== ì£¼ê°„ ì„±ê³¼ ë¦¬í¬íŠ¸ ===")
    print(f"ì´ ë§¤ì¶œ: {weekly_report['total_revenue']:,}ì›")
    print(f"ìˆœì´ìµ: {weekly_report['net_profit']:,}ì›")
    print(f"ROI: {weekly_report['roi']}%")
    print(f"ì‹ ê·œ ê³ ê°: {weekly_report['new_customers']}ëª…")
    
    # ë² ìŠ¤íŠ¸/ì›ŒìŠ¤íŠ¸ ìƒí’ˆ
    print("\n=== ë² ìŠ¤íŠ¸ ìƒí’ˆ TOP 5 ===")
    for i, product in enumerate(weekly_report['best_products'][:5], 1):
        print(f"{i}. {product['name']} - {product['revenue']:,}ì›")
    
    print("\n=== ê°œì„  í•„ìš” ìƒí’ˆ ===")
    for product in weekly_report['underperforming_products']:
        print(f"- {product['name']} (ë§¤ì¶œ: {product['revenue']:,}ì›)")
    
    return weekly_report
```

#### 2. ì¬ê³  ê´€ë¦¬
```python
# scripts/inventory_management.py
async def inventory_check():
    from src.inventory.stock_manager import StockManager
    
    stock_manager = StockManager()
    
    # ì¬ê³  ë¶€ì¡± ìƒí’ˆ
    low_stock = await stock_manager.get_low_stock_products()
    print(f"ì¬ê³  ë¶€ì¡± ìƒí’ˆ: {len(low_stock)}ê°œ")
    
    # ìë™ ì¬ê³  ë³´ì¶©
    for product in low_stock:
        if product['auto_reorder']:
            await stock_manager.create_reorder(product['id'])
            print(f"ìë™ ë°œì£¼: {product['name']}")
    
    # ê³¼ì¬ê³  ìƒí’ˆ
    overstock = await stock_manager.get_overstock_products()
    print(f"ê³¼ì¬ê³  ìƒí’ˆ: {len(overstock)}ê°œ")
    
    # í• ì¸ ì´ë²¤íŠ¸ ì œì•ˆ
    for product in overstock:
        suggested_discount = await stock_manager.suggest_discount(product)
        print(f"í• ì¸ ì œì•ˆ: {product['name']} - {suggested_discount}% í• ì¸")
```

### ğŸŒ™ ì €ë… ì²´í¬ë¦¬ìŠ¤íŠ¸ (18:00-19:00)

#### 1. ì¼ì¼ ë§¤ì¶œ ì •ì‚°
```python
# scripts/daily_settlement.py
async def daily_settlement():
    from src.order_processing.settlement_manager import SettlementManager
    
    settlement_manager = SettlementManager()
    today = datetime.now().date()
    
    # ì¼ì¼ ì •ì‚°
    daily_summary = await settlement_manager.process_daily_settlement(today)
    
    print("=== ì¼ì¼ ì •ì‚° ê²°ê³¼ ===")
    print(f"ì´ ì£¼ë¬¸: {daily_summary['total_orders']}ê±´")
    print(f"ì´ ë§¤ì¶œ: {daily_summary['total_revenue']:,}ì›")
    print(f"ì´ ë¹„ìš©: {daily_summary['total_costs']:,}ì›")
    print(f"ìˆœì´ìµ: {daily_summary['net_profit']:,}ì›")
    print(f"ì´ìµë¥ : {daily_summary['profit_margin']:.2f}%")
    
    # í”Œë«í¼ë³„ ë¶„ì„
    for platform, data in daily_summary['by_platform'].items():
        print(f"\n{platform}:")
        print(f"  ì£¼ë¬¸: {data['orders']}ê±´")
        print(f"  ë§¤ì¶œ: {data['revenue']:,}ì›")
        print(f"  ìˆ˜ìˆ˜ë£Œ: {data['fees']:,}ì›")
```

#### 2. ë‚´ì¼ ìŠ¤ì¼€ì¤„ í™•ì¸
```python
# scripts/tomorrow_schedule.py
async def check_tomorrow_schedule():
    from src.scheduling.task_scheduler import TaskScheduler
    
    scheduler = TaskScheduler()
    tomorrow = datetime.now().date() + timedelta(days=1)
    
    scheduled_tasks = await scheduler.get_daily_schedule(tomorrow)
    
    print("=== ë‚´ì¼ ì˜ˆì • ì‘ì—… ===")
    for task in scheduled_tasks:
        print(f"{task['time']} - {task['name']}")
        print(f"  ì„¤ëª…: {task['description']}")
        print(f"  ì˜ˆìƒ ì†Œìš”ì‹œê°„: {task['estimated_duration']}ë¶„")
    
    # ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡
    resource_forecast = await scheduler.forecast_resource_usage(tomorrow)
    print(f"\nì˜ˆìƒ CPU ì‚¬ìš©ë¥ : {resource_forecast['cpu']}%")
    print(f"ì˜ˆìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {resource_forecast['memory']}%")
```

## ğŸ“Š ì„±ê³¼ ëª¨ë‹ˆí„°ë§

### ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ êµ¬ì„±

#### KPI ëŒ€ì‹œë³´ë“œ
```python
# src/monitoring/kpi_dashboard.py
class KPIDashboard:
    def __init__(self):
        self.metrics_collector = MetricsCollector()
    
    async def get_realtime_kpis(self):
        return {
            # ë§¤ì¶œ ì§€í‘œ
            'revenue': {
                'today': await self.get_daily_revenue(),
                'this_month': await self.get_monthly_revenue(),
                'growth_rate': await self.calculate_growth_rate()
            },
            
            # ìš´ì˜ ì§€í‘œ
            'operations': {
                'active_products': await self.count_active_products(),
                'pending_orders': await self.count_pending_orders(),
                'system_uptime': await self.get_system_uptime(),
                'api_response_time': await self.get_avg_response_time()
            },
            
            # ê³ ê° ì§€í‘œ
            'customers': {
                'new_today': await self.count_new_customers_today(),
                'repeat_rate': await self.calculate_repeat_rate(),
                'satisfaction_score': await self.get_satisfaction_score()
            }
        }
    
    async def generate_alerts(self):
        kpis = await self.get_realtime_kpis()
        alerts = []
        
        # ë§¤ì¶œ ê°ì†Œ ì•Œë¦¼
        if kpis['revenue']['growth_rate'] < -10:
            alerts.append({
                'level': 'warning',
                'message': f"ë§¤ì¶œ ì„±ì¥ë¥  {kpis['revenue']['growth_rate']}% ê°ì†Œ"
            })
        
        # ì‹œìŠ¤í…œ ì„±ëŠ¥ ì•Œë¦¼
        if kpis['operations']['api_response_time'] > 2000:
            alerts.append({
                'level': 'critical',
                'message': f"API ì‘ë‹µì‹œê°„ {kpis['operations']['api_response_time']}ms ì´ˆê³¼"
            })
        
        return alerts
```

#### ë§¤ì¶œ íŠ¸ë˜í‚¹
```python
# src/monitoring/revenue_tracker.py
class RevenueTracker:
    def __init__(self):
        self.db = DatabaseManager()
    
    async def track_hourly_revenue(self):
        """ì‹œê°„ë³„ ë§¤ì¶œ ì¶”ì """
        query = """
        SELECT 
            DATE_TRUNC('hour', created_at) as hour,
            SUM(total_amount) as revenue,
            COUNT(*) as order_count
        FROM orders 
        WHERE created_at >= NOW() - INTERVAL '24 hours'
        GROUP BY hour
        ORDER BY hour
        """
        
        return await self.db.fetch_all(query)
    
    async def compare_with_last_week(self):
        """ì „ì£¼ ë™ì¼ ì‹œê°„ëŒ€ ë¹„êµ"""
        today_revenue = await self.get_today_revenue()
        last_week_revenue = await self.get_last_week_same_day_revenue()
        
        growth_rate = ((today_revenue - last_week_revenue) / last_week_revenue) * 100
        
        return {
            'today': today_revenue,
            'last_week': last_week_revenue,
            'growth_rate': growth_rate,
            'trend': 'up' if growth_rate > 0 else 'down'
        }
```

### ì•Œë¦¼ ì‹œìŠ¤í…œ

#### í…”ë ˆê·¸ë¨ ì•Œë¦¼
```python
# src/monitoring/telegram_notifier.py
import asyncio
import aiohttp

class TelegramNotifier:
    def __init__(self, bot_token, chat_id):
        self.bot_token = bot_token
        self.chat_id = chat_id
        self.base_url = f"https://api.telegram.org/bot{bot_token}"
    
    async def send_daily_report(self, report_data):
        message = f"""
ğŸ“Š **ì¼ì¼ ìš´ì˜ ë¦¬í¬íŠ¸**
ğŸ“… {report_data['date']}

ğŸ’° **ë§¤ì¶œ í˜„í™©**
â€¢ ì˜¤ëŠ˜ ë§¤ì¶œ: {report_data['revenue']:,}ì›
â€¢ ì£¼ë¬¸ ìˆ˜: {report_data['orders']}ê±´
â€¢ í‰ê·  ì£¼ë¬¸ì•¡: {report_data['avg_order']:,}ì›

ğŸ“¦ **ìƒí’ˆ í˜„í™©**
â€¢ í™œì„± ìƒí’ˆ: {report_data['active_products']}ê°œ
â€¢ ì‹ ê·œ ë“±ë¡: {report_data['new_products']}ê°œ
â€¢ ì¬ê³  ë¶€ì¡±: {report_data['low_stock']}ê°œ

âš ï¸ **ì£¼ì˜ì‚¬í•­**
{chr(10).join(f"â€¢ {alert}" for alert in report_data['alerts'])}
        """
        
        await self.send_message(message)
    
    async def send_alert(self, level, title, details):
        emoji = {
            'info': 'â„¹ï¸',
            'warning': 'âš ï¸',
            'critical': 'ğŸš¨'
        }
        
        message = f"""
{emoji.get(level, 'â„¹ï¸')} **{title}**

{details}

â° {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        """
        
        await self.send_message(message)
    
    async def send_message(self, text):
        url = f"{self.base_url}/sendMessage"
        data = {
            'chat_id': self.chat_id,
            'text': text,
            'parse_mode': 'Markdown'
        }
        
        async with aiohttp.ClientSession() as session:
            await session.post(url, json=data)
```

#### ì´ë©”ì¼ ì•Œë¦¼
```python
# src/monitoring/email_notifier.py
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class EmailNotifier:
    def __init__(self, smtp_config):
        self.smtp_config = smtp_config
    
    async def send_weekly_report(self, recipients, report_data):
        html_content = self.generate_html_report(report_data)
        
        msg = MIMEMultipart('alternative')
        msg['Subject'] = f"ì£¼ê°„ ë“œëì‰¬í•‘ ì„±ê³¼ ë¦¬í¬íŠ¸ - {report_data['week']}"
        msg['From'] = self.smtp_config['from_email']
        msg['To'] = ', '.join(recipients)
        
        html_part = MIMEText(html_content, 'html')
        msg.attach(html_part)
        
        with smtplib.SMTP(self.smtp_config['smtp_server'], self.smtp_config['port']) as server:
            server.starttls()
            server.login(self.smtp_config['username'], self.smtp_config['password'])
            server.send_message(msg)
    
    def generate_html_report(self, data):
        return f"""
        <html>
        <body>
            <h1>ì£¼ê°„ ì„±ê³¼ ë¦¬í¬íŠ¸</h1>
            <h2>ë§¤ì¶œ í˜„í™©</h2>
            <p>ì´ ë§¤ì¶œ: {data['revenue']:,}ì›</p>
            <p>ì„±ì¥ë¥ : {data['growth_rate']}%</p>
            
            <h2>ë² ìŠ¤íŠ¸ ìƒí’ˆ</h2>
            <ul>
            {''.join(f"<li>{product['name']} - {product['revenue']:,}ì›</li>" 
                    for product in data['best_products'])}
            </ul>
        </body>
        </html>
        """
```

## ğŸ’° ë¹„ìš© ìµœì í™”

### ì„œë²„ ë¹„ìš© ìµœì í™”

#### ìë™ ìŠ¤ì¼€ì¼ë§
```python
# src/optimization/auto_scaler.py
class AutoScaler:
    def __init__(self):
        self.metrics_collector = MetricsCollector()
        self.cloud_provider = CloudProviderManager()
    
    async def monitor_and_scale(self):
        """ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ë° ìë™ ìŠ¤ì¼€ì¼ë§"""
        while True:
            metrics = await self.metrics_collector.get_current_metrics()
            
            # CPU ì‚¬ìš©ë¥  ê¸°ë°˜ ìŠ¤ì¼€ì¼ë§
            if metrics['cpu_usage'] > 80:
                await self.scale_up()
            elif metrics['cpu_usage'] < 30:
                await self.scale_down()
            
            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì²´í¬
            if metrics['memory_usage'] > 85:
                await self.add_memory()
            
            await asyncio.sleep(300)  # 5ë¶„ë§ˆë‹¤ ì²´í¬
    
    async def schedule_cost_optimization(self):
        """ë¹„ìš© ìµœì í™” ìŠ¤ì¼€ì¤„ë§"""
        # ì•¼ê°„ ì‹œê°„ëŒ€ ë¦¬ì†ŒìŠ¤ ì¶•ì†Œ
        if 1 <= datetime.now().hour <= 6:
            await self.scale_down_for_night()
        
        # ì£¼ë§ ë¦¬ì†ŒìŠ¤ ì¡°ì •
        if datetime.now().weekday() in [5, 6]:
            await self.weekend_optimization()
```

#### í´ë¼ìš°ë“œ ë¹„ìš© ê´€ë¦¬
```python
# src/optimization/cost_manager.py
class CloudCostManager:
    def __init__(self):
        self.aws_client = boto3.client('ce')  # Cost Explorer
    
    async def get_daily_costs(self, days=7):
        """ì¼ì¼ ë¹„ìš© ì¶”ì """
        end_date = datetime.now().date()
        start_date = end_date - timedelta(days=days)
        
        response = self.aws_client.get_cost_and_usage(
            TimePeriod={
                'Start': str(start_date),
                'End': str(end_date)
            },
            Granularity='DAILY',
            Metrics=['BlendedCost']
        )
        
        return response['ResultsByTime']
    
    async def optimize_storage_costs(self):
        """ìŠ¤í† ë¦¬ì§€ ë¹„ìš© ìµœì í™”"""
        # ì˜¤ë˜ëœ ë¡œê·¸ íŒŒì¼ ì•„ì¹´ì´ë¸Œ
        old_logs = await self.find_old_log_files()
        for log_file in old_logs:
            await self.archive_to_glacier(log_file)
        
        # ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ ì •ë¦¬
        unused_images = await self.find_unused_images()
        for image in unused_images:
            await self.delete_image(image)
```

### API ë¹„ìš© ìµœì í™”

#### API í˜¸ì¶œ ìµœì í™”
```python
# src/optimization/api_optimizer.py
class APIOptimizer:
    def __init__(self):
        self.cache = Redis()
        self.call_tracker = APICallTracker()
    
    async def optimize_ai_calls(self):
        """AI API í˜¸ì¶œ ìµœì í™”"""
        # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ë¹„ìš© ì ˆê°
        pending_requests = await self.get_pending_ai_requests()
        
        if len(pending_requests) >= 10:
            # 10ê°œ ì´ìƒ ìŒ“ì´ë©´ ë°°ì¹˜ ì²˜ë¦¬
            await self.process_batch_ai_requests(pending_requests)
        
    async def implement_smart_caching(self):
        """ìŠ¤ë§ˆíŠ¸ ìºì‹± ì „ëµ"""
        # ìƒí’ˆ ì •ë³´ ìºì‹± (24ì‹œê°„)
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ê²°ê³¼ ìºì‹± (7ì¼)
        # AI ë¶„ì„ ê²°ê³¼ ìºì‹± (6ì‹œê°„)
        
        cache_strategies = {
            'product_info': {'ttl': 86400, 'compress': True},
            'image_processing': {'ttl': 604800, 'compress': True},
            'ai_analysis': {'ttl': 21600, 'compress': False}
        }
        
        for key_type, strategy in cache_strategies.items():
            await self.optimize_cache_strategy(key_type, strategy)
```

#### ë¹„ìš© ëª¨ë‹ˆí„°ë§
```python
# src/optimization/cost_monitor.py
class CostMonitor:
    def __init__(self):
        self.cost_tracker = CostTracker()
    
    async def generate_cost_report(self):
        """ë¹„ìš© ë¦¬í¬íŠ¸ ìƒì„±"""
        costs = await self.cost_tracker.get_monthly_costs()
        
        report = {
            'total_cost': costs['total'],
            'breakdown': {
                'server': costs['server'],
                'ai_api': costs['ai_api'],
                'storage': costs['storage'],
                'bandwidth': costs['bandwidth']
            },
            'optimization_suggestions': await self.get_optimization_suggestions(costs)
        }
        
        return report
    
    async def set_cost_alerts(self):
        """ë¹„ìš© ì•Œë¦¼ ì„¤ì •"""
        monthly_budget = 500000  # ì›” 50ë§Œì› ì˜ˆì‚°
        
        current_cost = await self.get_current_monthly_cost()
        
        if current_cost > monthly_budget * 0.8:
            await self.send_budget_alert(current_cost, monthly_budget)
        
        # ì¼ì¼ ë¹„ìš©ì´ ê¸‰ì¦í•œ ê²½ìš°
        daily_cost = await self.get_daily_cost()
        avg_daily_cost = await self.get_avg_daily_cost()
        
        if daily_cost > avg_daily_cost * 1.5:
            await self.send_spike_alert(daily_cost, avg_daily_cost)
```

## ğŸ” ë³´ì•ˆ ê´€ë¦¬

### ì ‘ê·¼ ì œì–´

#### ë‹¤ì¤‘ ì¸ì¦ ì‹œìŠ¤í…œ
```python
# src/security/mfa_manager.py
class MFAManager:
    def __init__(self):
        self.totp = pyotp.TOTP
        self.db = DatabaseManager()
    
    async def setup_mfa_for_user(self, user_id):
        """ì‚¬ìš©ì MFA ì„¤ì •"""
        secret = pyotp.random_base32()
        
        # QR ì½”ë“œ ìƒì„±
        totp_uri = pyotp.totp.TOTP(secret).provisioning_uri(
            name=f"user_{user_id}",
            issuer_name="Dropshipping System"
        )
        
        qr_code = self.generate_qr_code(totp_uri)
        
        # ë¹„ë°€í‚¤ ì €ì¥ (ì•”í˜¸í™”)
        await self.store_encrypted_secret(user_id, secret)
        
        return qr_code
    
    async def verify_mfa_token(self, user_id, token):
        """MFA í† í° ê²€ì¦"""
        secret = await self.get_user_secret(user_id)
        totp = pyotp.TOTP(secret)
        
        return totp.verify(token, valid_window=1)
```

#### IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸ ê´€ë¦¬
```python
# src/security/ip_manager.py
class IPWhitelistManager:
    def __init__(self):
        self.redis = Redis()
        self.db = DatabaseManager()
    
    async def add_trusted_ip(self, ip_address, description):
        """ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” IP ì¶”ê°€"""
        await self.db.execute(
            "INSERT INTO trusted_ips (ip_address, description, created_at) VALUES (?, ?, ?)",
            ip_address, description, datetime.now()
        )
        
        # Redisì— ìºì‹œ
        await self.redis.sadd("trusted_ips", ip_address)
    
    async def check_ip_access(self, ip_address):
        """IP ì ‘ê·¼ ê¶Œí•œ í™•ì¸"""
        # Redisì—ì„œ ë¹ ë¥¸ í™•ì¸
        is_trusted = await self.redis.sismember("trusted_ips", ip_address)
        
        if not is_trusted:
            # ì˜ì‹¬ìŠ¤ëŸ¬ìš´ ì ‘ê·¼ ë¡œê¹…
            await self.log_suspicious_access(ip_address)
            return False
        
        return True
```

### ë°ì´í„° ì•”í˜¸í™”

#### ë¯¼ê°ì •ë³´ ì•”í˜¸í™”
```python
# src/security/encryption_manager.py
from cryptography.fernet import Fernet
import base64

class EncryptionManager:
    def __init__(self):
        self.key = self.load_or_generate_key()
        self.cipher = Fernet(self.key)
    
    def encrypt_sensitive_data(self, data):
        """ë¯¼ê° ë°ì´í„° ì•”í˜¸í™”"""
        if isinstance(data, str):
            data = data.encode()
        
        encrypted = self.cipher.encrypt(data)
        return base64.b64encode(encrypted).decode()
    
    def decrypt_sensitive_data(self, encrypted_data):
        """ë¯¼ê° ë°ì´í„° ë³µí˜¸í™”"""
        encrypted_bytes = base64.b64decode(encrypted_data.encode())
        decrypted = self.cipher.decrypt(encrypted_bytes)
        return decrypted.decode()
    
    async def rotate_encryption_key(self):
        """ì•”í˜¸í™” í‚¤ ë¡œí…Œì´ì…˜"""
        old_key = self.key
        new_key = Fernet.generate_key()
        
        # ëª¨ë“  ì•”í˜¸í™”ëœ ë°ì´í„° ì¬ì•”í˜¸í™”
        await self.reencrypt_all_data(old_key, new_key)
        
        self.key = new_key
        self.cipher = Fernet(new_key)
```

### ë³´ì•ˆ ëª¨ë‹ˆí„°ë§

#### ì¹¨ì… íƒì§€ ì‹œìŠ¤í…œ
```python
# src/security/intrusion_detection.py
class IntrusionDetectionSystem:
    def __init__(self):
        self.failed_attempts = defaultdict(int)
        self.suspicious_patterns = []
    
    async def monitor_login_attempts(self):
        """ë¡œê·¸ì¸ ì‹œë„ ëª¨ë‹ˆí„°ë§"""
        while True:
            failed_logins = await self.get_recent_failed_logins()
            
            for attempt in failed_logins:
                ip = attempt['ip_address']
                self.failed_attempts[ip] += 1
                
                # 5íšŒ ì´ìƒ ì‹¤íŒ¨ì‹œ IP ì°¨ë‹¨
                if self.failed_attempts[ip] >= 5:
                    await self.block_ip(ip)
                    await self.send_security_alert(f"IP {ip} ì°¨ë‹¨ë¨ - ë°˜ë³µ ë¡œê·¸ì¸ ì‹¤íŒ¨")
            
            await asyncio.sleep(60)
    
    async def detect_unusual_activity(self):
        """ë¹„ì •ìƒ í™œë™ íƒì§€"""
        # API í˜¸ì¶œ íŒ¨í„´ ë¶„ì„
        api_calls = await self.get_recent_api_calls()
        
        for user_id, calls in api_calls.items():
            if len(calls) > 1000:  # ì‹œê°„ë‹¹ 1000íšŒ ì´ìƒ í˜¸ì¶œ
                await self.flag_suspicious_user(user_id)
            
            # ë¹„ì •ìƒì ì¸ ì‹œê°„ëŒ€ ì ‘ê·¼
            night_calls = [c for c in calls if 2 <= c.hour <= 5]
            if len(night_calls) > 50:
                await self.flag_night_activity(user_id)
```

## ğŸ’¾ ë°±ì—… ë° ë³µêµ¬

### ìë™ ë°±ì—… ì‹œìŠ¤í…œ

#### ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—…
```bash
#!/bin/bash
# scripts/backup_database.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups/database"
DB_NAME="dropshipping_db"

# PostgreSQL ë¤í”„
pg_dump $DB_NAME > "$BACKUP_DIR/db_backup_$DATE.sql"

# ì••ì¶•
gzip "$BACKUP_DIR/db_backup_$DATE.sql"

# S3ì— ì—…ë¡œë“œ
aws s3 cp "$BACKUP_DIR/db_backup_$DATE.sql.gz" s3://dropshipping-backups/database/

# ë¡œì»¬ íŒŒì¼ 7ì¼ í›„ ì‚­ì œ
find $BACKUP_DIR -name "*.sql.gz" -mtime +7 -delete

# ë°±ì—… ê²°ê³¼ ë¡œê¹…
if [ $? -eq 0 ]; then
    echo "$(date): ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì„±ê³µ - $DATE" >> /var/log/backup.log
else
    echo "$(date): ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ì‹¤íŒ¨" >> /var/log/backup.log
    # ì•Œë¦¼ ë°œì†¡
    python /scripts/send_backup_alert.py "database_backup_failed"
fi
```

#### íŒŒì¼ ì‹œìŠ¤í…œ ë°±ì—…
```python
# src/backup/file_backup_manager.py
import boto3
import os
from datetime import datetime

class FileBackupManager:
    def __init__(self):
        self.s3_client = boto3.client('s3')
        self.bucket_name = 'dropshipping-file-backups'
    
    async def backup_critical_files(self):
        """ì¤‘ìš” íŒŒì¼ ë°±ì—…"""
        critical_paths = [
            'config/',
            'logs/',
            'uploads/product_images/',
            'data/cache/',
            '.env'
        ]
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        for path in critical_paths:
            if os.path.exists(path):
                if os.path.isfile(path):
                    await self.backup_single_file(path, timestamp)
                else:
                    await self.backup_directory(path, timestamp)
    
    async def backup_single_file(self, file_path, timestamp):
        """ë‹¨ì¼ íŒŒì¼ ë°±ì—…"""
        s3_key = f"files/{timestamp}/{file_path}"
        
        try:
            self.s3_client.upload_file(file_path, self.bucket_name, s3_key)
            print(f"ë°±ì—… ì™„ë£Œ: {file_path} -> {s3_key}")
        except Exception as e:
            print(f"ë°±ì—… ì‹¤íŒ¨: {file_path} - {str(e)}")
    
    async def backup_directory(self, dir_path, timestamp):
        """ë””ë ‰í† ë¦¬ ë°±ì—…"""
        for root, dirs, files in os.walk(dir_path):
            for file in files:
                file_path = os.path.join(root, file)
                relative_path = os.path.relpath(file_path)
                await self.backup_single_file(relative_path, timestamp)
```

### ë³µêµ¬ ì ˆì°¨

#### ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
```python
# src/backup/recovery_manager.py
class RecoveryManager:
    def __init__(self):
        self.db_manager = DatabaseManager()
        self.s3_client = boto3.client('s3')
    
    async def restore_database(self, backup_date):
        """ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬"""
        print(f"ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ ì‹œì‘: {backup_date}")
        
        # 1. ë°±ì—… íŒŒì¼ ë‹¤ìš´ë¡œë“œ
        backup_file = f"db_backup_{backup_date}.sql.gz"
        s3_key = f"database/{backup_file}"
        
        self.s3_client.download_file(
            'dropshipping-backups', 
            s3_key, 
            f"/tmp/{backup_file}"
        )
        
        # 2. ì••ì¶• í•´ì œ
        os.system(f"gunzip /tmp/{backup_file}")
        
        # 3. í˜„ì¬ ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… (ì•ˆì „ì¥ì¹˜)
        current_backup = f"pre_restore_{datetime.now().strftime('%Y%m%d_%H%M%S')}.sql"
        os.system(f"pg_dump dropshipping_db > /tmp/{current_backup}")
        
        # 4. ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬
        sql_file = f"/tmp/db_backup_{backup_date}.sql"
        restore_command = f"psql dropshipping_db < {sql_file}"
        
        result = os.system(restore_command)
        
        if result == 0:
            print("ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ ì™„ë£Œ")
            return True
        else:
            print("ë°ì´í„°ë² ì´ìŠ¤ ë³µêµ¬ ì‹¤íŒ¨")
            # ì›ë³¸ ìƒíƒœë¡œ ë¡¤ë°±
            os.system(f"psql dropshipping_db < /tmp/{current_backup}")
            return False
    
    async def restore_files(self, backup_timestamp):
        """íŒŒì¼ ì‹œìŠ¤í…œ ë³µêµ¬"""
        print(f"íŒŒì¼ ë³µêµ¬ ì‹œì‘: {backup_timestamp}")
        
        # S3ì—ì„œ ë°±ì—… íŒŒì¼ ëª©ë¡ ì¡°íšŒ
        response = self.s3_client.list_objects_v2(
            Bucket='dropshipping-file-backups',
            Prefix=f'files/{backup_timestamp}/'
        )
        
        for obj in response.get('Contents', []):
            s3_key = obj['Key']
            local_path = s3_key.replace(f'files/{backup_timestamp}/', '')
            
            # ë””ë ‰í† ë¦¬ ìƒì„±
            os.makedirs(os.path.dirname(local_path), exist_ok=True)
            
            # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
            self.s3_client.download_file(
                'dropshipping-file-backups',
                s3_key,
                local_path
            )
            
            print(f"ë³µêµ¬ ì™„ë£Œ: {local_path}")
```

#### ì¬í•´ ë³µêµ¬ ê³„íš
```python
# src/backup/disaster_recovery.py
class DisasterRecoveryPlan:
    def __init__(self):
        self.recovery_steps = [
            self.assess_damage,
            self.restore_critical_services,
            self.restore_database,
            self.restore_files,
            self.verify_integrity,
            self.resume_operations
        ]
    
    async def execute_recovery_plan(self):
        """ì¬í•´ ë³µêµ¬ ê³„íš ì‹¤í–‰"""
        print("=== ì¬í•´ ë³µêµ¬ ê³„íš ì‹¤í–‰ ì‹œì‘ ===")
        
        for step_num, step_func in enumerate(self.recovery_steps, 1):
            print(f"Step {step_num}: {step_func.__name__}")
            
            try:
                success = await step_func()
                if not success:
                    print(f"Step {step_num} ì‹¤íŒ¨ - ë³µêµ¬ ì¤‘ë‹¨")
                    return False
                print(f"Step {step_num} ì™„ë£Œ")
            except Exception as e:
                print(f"Step {step_num} ì˜¤ë¥˜: {str(e)}")
                return False
        
        print("=== ì¬í•´ ë³µêµ¬ ê³„íš ì™„ë£Œ ===")
        return True
    
    async def assess_damage(self):
        """í”¼í•´ ìƒí™© í‰ê°€"""
        # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
        # ë°ì´í„° ë¬´ê²°ì„± í™•ì¸
        # ë³µêµ¬ ìš°ì„ ìˆœìœ„ ê²°ì •
        return True
    
    async def restore_critical_services(self):
        """í•µì‹¬ ì„œë¹„ìŠ¤ ë³µêµ¬"""
        # ë°ì´í„°ë² ì´ìŠ¤ ì„œë²„ ì‹œì‘
        # ì›¹ ì„œë²„ ì‹œì‘
        # ìºì‹œ ì„œë²„ ì‹œì‘
        return True
```

## ğŸš€ ìŠ¤ì¼€ì¼ë§ ì „ëµ

### ìˆ˜í‰ì  í™•ì¥

#### ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¶„ë¦¬
```python
# src/scaling/service_splitter.py
class ServiceSplitter:
    def __init__(self):
        self.services = {
            'product_collection': ['gentrade', 'ownersclan', 'domemegguk'],
            'ai_processing': ['analysis', 'naming', 'optimization'],
            'marketplace_api': ['coupang', 'naver', '11st'],
            'order_processing': ['monitoring', 'fulfillment', 'tracking']
        }
    
    async def split_services(self):
        """ì„œë¹„ìŠ¤ ë¶„ë¦¬ ë° ë°°í¬"""
        for service_name, components in self.services.items():
            await self.create_service_container(service_name, components)
            await self.setup_load_balancer(service_name)
            await self.configure_auto_scaling(service_name)
    
    async def create_service_container(self, service_name, components):
        """ì„œë¹„ìŠ¤ ì»¨í…Œì´ë„ˆ ìƒì„±"""
        dockerfile_content = self.generate_dockerfile(service_name, components)
        
        with open(f"docker/{service_name}/Dockerfile", 'w') as f:
            f.write(dockerfile_content)
        
        # Docker ì´ë¯¸ì§€ ë¹Œë“œ ë° ë°°í¬
        build_command = f"docker build -t {service_name}:latest docker/{service_name}/"
        os.system(build_command)
```

#### ë¡œë“œ ë°¸ëŸ°ì‹±
```python
# src/scaling/load_balancer.py
class LoadBalancer:
    def __init__(self):
        self.servers = {}
        self.health_checker = HealthChecker()
    
    async def distribute_requests(self, service_name, request):
        """ìš”ì²­ ë¶„ì‚°"""
        available_servers = await self.get_healthy_servers(service_name)
        
        if not available_servers:
            raise Exception(f"No healthy servers for {service_name}")
        
        # ë¼ìš´ë“œ ë¡œë¹ˆ ë°©ì‹
        server = self.select_server_round_robin(available_servers)
        
        # ì„œë²„ ë¶€í•˜ ê³ ë ¤
        if server['load'] > 80:
            server = self.select_least_loaded_server(available_servers)
        
        return await self.forward_request(server, request)
    
    async def auto_scale_servers(self, service_name):
        """ìë™ ì„œë²„ í™•ì¥"""
        metrics = await self.get_service_metrics(service_name)
        
        if metrics['avg_cpu'] > 70 and metrics['avg_memory'] > 80:
            await self.add_server_instance(service_name)
        
        elif metrics['avg_cpu'] < 20 and metrics['avg_memory'] < 30:
            await self.remove_server_instance(service_name)
```

### ìˆ˜ì§ì  í™•ì¥

#### ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
```python
# src/scaling/resource_monitor.py
class ResourceMonitor:
    def __init__(self):
        self.thresholds = {
            'cpu': {'scale_up': 80, 'scale_down': 20},
            'memory': {'scale_up': 85, 'scale_down': 30},
            'disk': {'scale_up': 90, 'scale_down': 50}
        }
    
    async def monitor_resources(self):
        """ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
        while True:
            resources = await self.get_current_resources()
            
            for resource_type, usage in resources.items():
                await self.check_scaling_needs(resource_type, usage)
            
            await asyncio.sleep(300)  # 5ë¶„ë§ˆë‹¤ ì²´í¬
    
    async def check_scaling_needs(self, resource_type, usage):
        """ìŠ¤ì¼€ì¼ë§ í•„ìš”ì„± í™•ì¸"""
        thresholds = self.thresholds[resource_type]
        
        if usage > thresholds['scale_up']:
            await self.trigger_scale_up(resource_type)
        elif usage < thresholds['scale_down']:
            await self.trigger_scale_down(resource_type)
```

## âš–ï¸ ë²•ì  ì¤€ìˆ˜ì‚¬í•­

### ê°œì¸ì •ë³´ë³´í˜¸

#### GDPR ì¤€ìˆ˜
```python
# src/compliance/gdpr_manager.py
class GDPRComplianceManager:
    def __init__(self):
        self.db = DatabaseManager()
        self.encryption = EncryptionManager()
    
    async def handle_data_request(self, user_id, request_type):
        """ê°œì¸ì •ë³´ ìš”ì²­ ì²˜ë¦¬"""
        if request_type == "access":
            return await self.provide_user_data(user_id)
        elif request_type == "deletion":
            return await self.delete_user_data(user_id)
        elif request_type == "portability":
            return await self.export_user_data(user_id)
    
    async def anonymize_old_data(self):
        """ì˜¤ë˜ëœ ë°ì´í„° ìµëª…í™”"""
        cutoff_date = datetime.now() - timedelta(days=730)  # 2ë…„
        
        # ê°œì¸ì •ë³´ ìµëª…í™”
        await self.db.execute("""
            UPDATE customers 
            SET name = 'ANONYMIZED', 
                email = CONCAT('anon_', id, '@example.com'),
                phone = NULL,
                address = NULL
            WHERE created_at < %s
        """, cutoff_date)
```

### ì „ììƒê±°ë˜ë²• ì¤€ìˆ˜

#### í‘œì‹œê´‘ê³ ë²• ì¤€ìˆ˜
```python
# src/compliance/advertising_compliance.py
class AdvertisingComplianceChecker:
    def __init__(self):
        self.prohibited_terms = [
            "100% íš¨ê³¼", "ì¦‰ì‹œ íš¨ê³¼", "ë¶€ì‘ìš© ì—†ìŒ",
            "ì„¸ê³„ ìµœì´ˆ", "ì„¸ê³„ ìœ ì¼", "ì™„ì¹˜"
        ]
    
    async def check_product_description(self, description):
        """ìƒí’ˆ ì„¤ëª… ì¤€ìˆ˜ì„± ê²€ì‚¬"""
        violations = []
        
        for term in self.prohibited_terms:
            if term in description:
                violations.append(f"ê¸ˆì§€ ìš©ì–´ ì‚¬ìš©: {term}")
        
        # ê³¼ì¥ ê´‘ê³  íƒì§€
        if self.detect_exaggeration(description):
            violations.append("ê³¼ì¥ ê´‘ê³  ì˜ì‹¬")
        
        return {
            'compliant': len(violations) == 0,
            'violations': violations
        }
    
    def detect_exaggeration(self, text):
        """ê³¼ì¥ ê´‘ê³  íƒì§€"""
        exaggeration_patterns = [
            r'\d+%\s*íš¨ê³¼',
            r'ì¦‰ì‹œ|ë°”ë¡œ|ë‹¹ì¥',
            r'ìµœê³ |ìµœëŒ€|ìµœìƒ'
        ]
        
        for pattern in exaggeration_patterns:
            if re.search(pattern, text):
                return True
        
        return False
```

### ì„¸ê¸ˆ ê´€ë¦¬

#### ë¶€ê°€ê°€ì¹˜ì„¸ ê³„ì‚°
```python
# src/compliance/tax_manager.py
class TaxManager:
    def __init__(self):
        self.vat_rate = 0.10  # 10%
        self.db = DatabaseManager()
    
    async def calculate_monthly_vat(self, year, month):
        """ì›”ë³„ ë¶€ê°€ê°€ì¹˜ì„¸ ê³„ì‚°"""
        sales_data = await self.get_monthly_sales(year, month)
        purchase_data = await self.get_monthly_purchases(year, month)
        
        sales_vat = sum(sale['amount'] * self.vat_rate for sale in sales_data)
        purchase_vat = sum(purchase['amount'] * self.vat_rate for purchase in purchase_data)
        
        net_vat = sales_vat - purchase_vat
        
        return {
            'sales_vat': sales_vat,
            'purchase_vat': purchase_vat,
            'net_vat': net_vat,
            'payment_due': max(0, net_vat)
        }
    
    async def generate_tax_report(self, quarter):
        """ë¶„ê¸°ë³„ ì„¸ë¬´ ë³´ê³ ì„œ ìƒì„±"""
        months = self.get_quarter_months(quarter)
        quarterly_data = {}
        
        for month in months:
            monthly_vat = await self.calculate_monthly_vat(2024, month)
            quarterly_data[f"month_{month}"] = monthly_vat
        
        return self.format_tax_report(quarterly_data)
```

ì´ ìš´ì˜ ê°€ì´ë“œë¥¼ í†µí•´ ë“œëì‰¬í•‘ ìë™í™” ì‹œìŠ¤í…œì„ ì•ˆì •ì ì´ê³  íš¨ìœ¨ì ìœ¼ë¡œ ìš´ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì •ê¸°ì ì¸ ëª¨ë‹ˆí„°ë§ê³¼ ìµœì í™”ë¥¼ í†µí•´ ì§€ì†ì ì¸ ì„±ì¥ì„ ë‹¬ì„±í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.